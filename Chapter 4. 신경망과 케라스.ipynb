{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터를 네트워크에 맞게 변형\n",
    "\n",
    "# 여기서는 2차원으로 변형하고 float형으로 변환한 후에\n",
    "# 0부터 1 사이의 값을 가지도록 스케일 변환\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_train = x_train/255.\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_test = x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 레이블을 네트워크에 맞게 변형\n",
    "# 정수가 저장된 클래스 레이블을 0, 1로 구성된 벡터로 변환 : 원핫(one-hot) 벡터\n",
    "# to_categorical\n",
    "\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 → 10\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential API를 사용하여 다층 신경망 구축\n",
    "\n",
    "- Sequential API에서는 준비된 레이어를 add 메서드로 추가하는 것만으로 간단히 모델 구축 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구축 준비\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# 중간층 추가\n",
    "\n",
    "# Dense 레이어를 이용해서 완전연결 계층 추가\n",
    "# 완전연결 계층 : 모든 입력이 모든 뉴런과 결합된 층\n",
    "# 입력에 가중치를 곱한 후 더한다\n",
    "# 케라스에서는 Sequential API의 add 메서드를 사용해서 중간층 추가\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "model.add(\n",
    "    Dense(\n",
    "        units = 64,             # 뉴런의 수 (출력 차원)\n",
    "        input_shape=(784, ),    # 입력되는 텐서의 형태\n",
    "        activation = 'relu'     # 활성화 함수의 종류\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층 추가\n",
    "\n",
    "# Dense 레이어를 한층 더 추가해서 출력층 추가\n",
    "# MNIST 데이터는 0부터 9까지의 숫자 중에서 하나를 레이블로 가진 10 클래스 분류\n",
    "# → 모델의 출력 차원을 10으로 지정\n",
    "\n",
    "# 1층에서는 입력되는 텐서의 형태를 input_shape로 지정했지만,\n",
    "# 2층 이후에는 케라스가 input_shape를 자동으로 계산해주므로 생략 가능\n",
    "\n",
    "model.add(\n",
    "    Dense(\n",
    "        units = 10,\n",
    "        activation = 'softmax'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차엔트로피 : 두 개의 확률 분포 사이에 정의된 척도\n",
    "# 분류 문제에서는 이 값이 작아지도록 학습\n",
    "# 케라스에서는 이진 분류일 때는 binary_crossentropy\n",
    "#              다중 분류일 때는 categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.1768 - acc: 0.9483 - val_loss: 0.1411 - val_acc: 0.9578\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 5s 106us/sample - loss: 0.1230 - acc: 0.9637 - val_loss: 0.1258 - val_acc: 0.9641\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.0947 - acc: 0.9719 - val_loss: 0.1056 - val_acc: 0.9693\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.0768 - acc: 0.9769 - val_loss: 0.1065 - val_acc: 0.9689\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0638 - acc: 0.9802 - val_loss: 0.1102 - val_acc: 0.9671\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.0520 - acc: 0.9840 - val_loss: 0.0959 - val_acc: 0.9725\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0453 - acc: 0.9861 - val_loss: 0.0925 - val_acc: 0.9737\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 5s 105us/sample - loss: 0.0375 - acc: 0.9887 - val_loss: 0.0993 - val_acc: 0.9712\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.0328 - acc: 0.9894 - val_loss: 0.0979 - val_acc: 0.9736\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.0274 - acc: 0.9918 - val_loss: 0.0992 - val_acc: 0.9728\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.0230 - acc: 0.9930 - val_loss: 0.1105 - val_acc: 0.9730\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.0206 - acc: 0.9937 - val_loss: 0.1097 - val_acc: 0.9724\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0182 - acc: 0.9943 - val_loss: 0.1178 - val_acc: 0.9711\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0150 - acc: 0.9957 - val_loss: 0.1069 - val_acc: 0.9737\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0138 - acc: 0.9963 - val_loss: 0.1078 - val_acc: 0.9738\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.0130 - acc: 0.9958 - val_loss: 0.1099 - val_acc: 0.9744\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0095 - acc: 0.9978 - val_loss: 0.1206 - val_acc: 0.9729\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0095 - acc: 0.9974 - val_loss: 0.1213 - val_acc: 0.9731\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0079 - acc: 0.9980 - val_loss: 0.1180 - val_acc: 0.9753\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0090 - acc: 0.9974 - val_loss: 0.1256 - val_acc: 0.9730\n"
     ]
    }
   ],
   "source": [
    "# 구축한 모델 학습\n",
    "\n",
    "# 학습할 때 각 에폭에서 손실 함수의 값과 분류 정확도를 얻으려면 callbacks 모듈을 이용\n",
    "\n",
    "# acc : 구축한 모델의 학습용 데이터에 대한 분류 정확도\n",
    "# loss : (구축한 모델의) 손실 함수의 값\n",
    "# val_acc : 구축한 모델의 검증용 데이터에 대한 분류 정확도\n",
    "# val_loss : (구축한 모델의) 손실 함수의 값\n",
    "\n",
    "# Adam을 이용한 모델의 MNIST 데이터 학습\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "tsb = TensorBoard(log_dir='./logs')\n",
    "history_adam = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size = 32,\n",
    "    epochs = 20,\n",
    "    validation_split = 0.2,\n",
    "    callbacks = [tsb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional API로 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API를 이용한 모델 구축 준비\n",
    "from tensorflow.python.keras.datasets import mnist\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.keras.layers import Input, Dense\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_train = x_train/255.\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_test = x_test/255.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "tsb = TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API로 모델 구축\n",
    "\n",
    "input = Input( shape=(784, ) )\n",
    "middle = Dense( units=64, activation='relu' )( input )\n",
    "output = Dense( units=10, activation='softmax' )( middle )\n",
    "model = Model( inputs=[input], outputs=[output] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API에서도 레이어 객체를 사용해서\n",
    "# 텐서를 다음 층의 인수로 전달함으로써 모델을 구축할 수 있다\n",
    "\n",
    "# Functional API에서는 model 클래스의 인수로\n",
    "# inputs의 입력 텐서와 outputs의 출력 텐서를 지정하는 방법으로 모델 구축\n",
    "\n",
    "# 구축한 모델은 Sequential API로 구축한 모델과 같아서\n",
    "# 모델 컴파일과 학습으로\n",
    "# compile과 fit 메서드 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구축한 모델의 컴파일\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.3246 - acc: 0.9087 - val_loss: 0.1879 - val_acc: 0.9463\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.1597 - acc: 0.9535 - val_loss: 0.1364 - val_acc: 0.9607\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.1163 - acc: 0.9656 - val_loss: 0.1204 - val_acc: 0.9650\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.0910 - acc: 0.9738 - val_loss: 0.1135 - val_acc: 0.9657\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0743 - acc: 0.9775 - val_loss: 0.1050 - val_acc: 0.9684\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0616 - acc: 0.9818 - val_loss: 0.1005 - val_acc: 0.9705\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0531 - acc: 0.9839 - val_loss: 0.1023 - val_acc: 0.9693\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0450 - acc: 0.9865 - val_loss: 0.0977 - val_acc: 0.9703\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0390 - acc: 0.9886 - val_loss: 0.1002 - val_acc: 0.9715\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.0344 - acc: 0.9896 - val_loss: 0.1052 - val_acc: 0.9701\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0290 - acc: 0.9914 - val_loss: 0.1065 - val_acc: 0.9701\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0252 - acc: 0.9928 - val_loss: 0.1023 - val_acc: 0.9730\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.0240 - acc: 0.9928 - val_loss: 0.1110 - val_acc: 0.9709\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0199 - acc: 0.9945 - val_loss: 0.1213 - val_acc: 0.9686\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.0173 - acc: 0.9947 - val_loss: 0.1104 - val_acc: 0.9713\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0165 - acc: 0.9951 - val_loss: 0.1092 - val_acc: 0.9721\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.0134 - acc: 0.9960 - val_loss: 0.1187 - val_acc: 0.9732\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.0130 - acc: 0.9962 - val_loss: 0.1189 - val_acc: 0.9714\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0123 - acc: 0.9961 - val_loss: 0.1223 - val_acc: 0.9727\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.0094 - acc: 0.9974 - val_loss: 0.1263 - val_acc: 0.9701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cbaf08dc88>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST 데이터 세트 학습\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size = 32,\n",
    "    epochs = 20,\n",
    "    # 학습할 때 각 에폭에서 손실 함수의 값과 분류 정확도를 얻으려면 callbacks 모듈\n",
    "    callbacks = [tsb],  \n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
